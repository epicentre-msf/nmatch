% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmatch.R
\name{nmatch}
\alias{nmatch}
\title{Compare sets of proper names accounting for common types of variation in
format and style}
\usage{
nmatch(
  x,
  y,
  token_split = "[-_[:space:]]+",
  nchar_min = 2L,
  dist_method = "osa",
  dist_max = 1L,
  std = name_standardize,
  ...,
  return_full = FALSE,
  eval_fn = match_eval,
  eval_params = list(n_match_crit = 2)
)
}
\arguments{
\item{x, y}{Vectors of proper names to compare. Must be of same length.}

\item{token_split}{Regex pattern to split strings into tokens. Defaults to
\code{"[-_[:space:]]+"}, which splits at each sequence of one more dash,
underscore, or space character.}

\item{nchar_min}{Minimum token size to compare. Defaults to \code{2L}.}

\item{dist_method}{Method to use for string distance calculation (see
\link[stringdist]{stringdist-metrics}). Defaults to \code{"osa"}.}

\item{dist_max}{Maximum string distance to use to classify matching tokens
(i.e. tokens with a string distance less than or equal to \code{dist_max} will
be considered matching). Defaults to \code{1L}.}

\item{std}{Function to standardize strings during matching. Defaults to
\code{\link{name_standardize}}. Set to \code{NULL} to omit standardization.}

\item{...}{additional arguments passed to \code{std()}}

\item{return_full}{Logical indicating whether to return data frame with full
summary of match details (\code{TRUE}), or only a logical vector corresponding
to final match status (\code{FALSE}). Defaults to \code{FALSE}.}

\item{eval_fn}{Function to determine overall match status. Defaults to
\code{\link{match_eval}}. See section \emph{Custom classification functions} for
more details.}

\item{eval_params}{List of additional arguments passed to \code{eval_fn}}
}
\value{
If \code{return_full = FALSE} (the default), returns a logical vector indicating
which elements of \code{x} and \code{y} are matches.

If \code{return_full = TRUE}, returns a tibble-style data frame summarizing the
match details, including columns:
\itemize{
\item \code{is_match}: logical vector indicating overall match status
\item \code{k_x}: number of tokens in \code{x} (excludes tokens smaller than \code{nchar_min})
\item \code{k_y}: number of tokens in \code{y} (excludes tokens smaller than \code{nchar_min})
\item \code{k_align}: number of aligned tokens (i.e. \code{min(k_x, k_y)})
\item \code{n_match}: number of aligned tokens that match (i.e. distance <= \code{dist_max})
\item \code{dist_total}: summed string distance across aligned tokens
}
}
\description{
Compare proper names across two sources using string-standardization to
account for variation in punctuation, accents, and character case,
token-permutation to account for variation in name order, and fuzzy matching
to handle alternate spellings. The specific steps are:
\enumerate{
\item Standardize strings. The default function is
\code{\link{name_standardize}} which removes accents and punctuation,
standardizes case, and removes extra whitespace. E.g. "Brontë, Emily J." is
standardized to "BRONTE EMILY J".
\item Tokenize standardized names, optionally retaining only tokens larger than
a given nchar limit.
\item For each pair of names, calculate string distance between all combinations
of tokens, and find the best overall token alignment (i.e. the alignment that
minimizes the summed string distance). If two names being compared differ in
their number of tokens, the alignment is made with respect to the smaller
number of tokens. E.g. If comparing "Angela Dorothea Merkel" to "Merkel
Angela", the token "Dorothea" would ultimately be omitted from the best
alignment.
\item Summarize the number of tokens in each name, the number of tokens in the
best alignment, the number of aligned tokens that match (i.e. string
distance less than or equal to the defined threshold), and the summed string
distance of the best alignment.
\item Classify overall match status (TRUE/FALSE) based on match details
described in (4). By default, two names are considered to be matching if two
or more tokens match across names (e.g. "Merkel Angela" matches "Angela
Dorothea Merkel"), or if both names consist of only a single token which is
matching (e.g. "Beyonce" matches "Beyoncé").
}
}
\examples{
names1 <- c(
  "Angela Dorothea Merkel",
  "Emmanuel Jean-Michel Fr\u00e9d\u00e9ric Macron",
  "Mette Frederiksen",
  "Katrin Jakobsd\u00f3ttir",
  "Pedro S\u00e1nchez P\u00e9rez-Castej\u00f3n"
)

names2 <- c(
  "MERKEL, Angela",
  "MACRON, Emmanuel J.-M. F.",
  "FREDERICKSON, Mette",
  "JAKOBSDOTTIR  Kathríne",
  "PEREZ-CASTLEJON, Pedro"
)

# return logical vector specifying which names are matches
nmatch(names1, names2)

# increase the threshold string distance to allow for 'fuzzier' matches
nmatch(names1, names2, dist_max = 2)

# return data frame with full match details
nmatch(names1, names2, return_full = TRUE)

# use a custom function to classify matches
classify_matches <- function(k_align, n_match, dist_total, ...) {
  n_match == k_align & dist_total < 2
}

nmatch(names1, names2, return_full = TRUE, eval_fn = classify_matches)

}
